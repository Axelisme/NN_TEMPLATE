architectures: &Arch
  model:
    select: 'TemplateModel'
    TemplateModel:
      module: 'custom.model.template'
      args:
        input_size: 128
        num_classes: &N 8
        hidden_size: 256

  optimizer:
    select: 'AdamW'
    AdamW: &AdamW_args
      module: 'torch.optim'
      args:
        lr: 0.0003
    Adam: *AdamW_args

  scheduler:
    select: 'ExponentialLR'
    ExponentialLR:
      module: 'torch.optim.lr_scheduler'
      args:
        gamma: 0.9995
    ConstantLR:
      module: 'torch.optim.lr_scheduler'
      args:
        total_iters: 0

  loss:
    select: 'CrossEntropyLoss'
    CrossEntropyLoss:
      module: 'torch.nn'
      args: {}

  metric:
    select:
      - 'MulticlassAccuracy'
    use_loss: True
    MulticlassAccuracy:
      module: 'torchmetrics.classification'
      args:
        num_classes: *N
        average: 'macro'


data:
  datasets:
    train_hdf5_template:
      name: 'HDF5DataSet'
      module: 'custom.dataset.hdf5_dataset'
      args:
        dataset_path: './data/processed/template/train.h5'
    valid_hdf5_template:
      name: 'HDF5DataSet'
      module: 'custom.dataset.hdf5_dataset'
      args:
        dataset_path: './data/processed/template/valid.h5'
    test_hdf5_template:
      name: 'HDF5DataSet'
      module: 'custom.dataset.hdf5_dataset'
      args:
        dataset_path: './data/processed/template/test.h5'

  dataloaders:
    train_loader:
      args:
        batch_size: 32
        shuffle: True
        pin_memory: True
        num_workers: 0
      dataset: 'train_hdf5_template'
    valid_loader:
      args:
        batch_size: 1
        shuffle: False
        pin_memory: True
        num_workers: 0
      dataset: 'valid_hdf5_template'
    test_loader:
      args:
        batch_size: 1
        shuffle: False
        pin_memory: True
        num_workers: 0
      dataset: 'test_hdf5_template'


runner:
  step_mod: 'grad' # 'epoch' or 'grad'
  total_steps: 1100
  log_freq: 100
  dev_freq: 1000
  save_freq: 500
  trainer_args:
    gradient_accumulation_steps: 1
  valider_args: {}


ckpt:
  save_mod : 'max'
  check_metrics:
    - 'MulticlassAccuracy'
  ckpt_dir: ~  # default: './data/saved_models/{name}'
  keep_num: 3


WandB:
  project: &P 'Template_project'
  init_args:
    name: 'Template_model'
    config: *Arch
  watch_args:
    log: 'all'
    log_freq: 1000
  sweep:
    num_trials: 30
    config:
      name: 'Template_sweep'
      method: 'random'
      metric:
        name: 'Valid_loss'
        goal: 'minimize'
      parameters:
        runner:
          parameters:
            total_steps:
              value: 100
            log_freq:
              value: 50
            dev_freq:
              value: 50
        architectures:
          parameters:
            optimizer:
              parameters:
                select:
                  values:
                    - 'AdamW'
                    - 'Adam'
                AdamW:
                  parameters:
                    args:
                      parameters:
                        lr:
                          values:
                            - 0.0001
                            - 0.0003
                            - 0.0005
        data:
          parameters:
            train_loader:
              parameters:
                args:
                  parameters:
                    batch_size:
                      values:
                        - 16
                        - 32
                        - 64

