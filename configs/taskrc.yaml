runner: &Runner
  step_mod: 'grad' # 'epoch' or 'grad'
  total_steps: 2000
  log_freq: 100
  valid_freq: 1000
  save_freq: 500
  seed: 0
  trainer_kwargs:
    grad_acc_steps: 1
  valider_kwargs: {}

optimizer:
  select: 'AdamW'
  AdamW:
    name: 'AdamW'
    module: 'torch.optim'
    kwargs:
      lr: 0.0003

scheduler:
  select: 'ConstantLR'
  ConstantLR:
    name: 'ConstantLR'
    module: 'torch.optim.lr_scheduler'
    kwargs:
      total_iters: 0

loss:
  select: 'CELoss'
  CELoss:
    name: 'CrossEntropyLoss'
    module: 'torch.nn'
    kwargs: {}

metric:
  use_loss: True
  loss_name: &Loss_name 'loss'
  apply_on_train: True
  selects:
    - &Acc 'acc'
  acc:
    name: 'MulticlassAccuracy'
    module: 'torchmetrics.classification'
    kwargs:
      num_classes: 8
      average: 'macro'

ckpt:
  check_metrics:
    - {name: *Acc, mod: 'max'}
    - {name: *Loss_name, mod: 'min'}
  check_datasets: ~ # None implies all datasets
  keep_num: 3       # -1 implies keep all
  metric_compare_first: False  # compare metrics first, else compare datasets first

data:
  train_dataset: 'train'                 # select train dataset
  valid_datasets: ['devel', 'test']      # select valid datasets
  batch_preprocess: False # apply to all datasets
  augment: True           # only apply on train dataset, before batch_preprocess

  train_dataloader: 'trainloader'
  valid_dataloader: 'validloader'
  batch_preprocess_fn: ~
  augment_fn: 'batch_augment_fn'

  datasets:
    train:
      name: 'HDF5DataSet'
      module: 'custom.dataset.hdf5_dataset'
      kwargs:
        dataset_path: './data/processed/template/train.h5'
    devel:
      name: 'HDF5DataSet'
      module: 'custom.dataset.hdf5_dataset'
      kwargs:
        dataset_path: './data/processed/template/devel.h5'
    test:
      name: 'HDF5DataSet'
      module: 'custom.dataset.hdf5_dataset'
      kwargs:
        dataset_path: './data/processed/template/test.h5'

  dataloaders:
    trainloader:
      kwargs:
        batch_size: 32
        shuffle: True
        pin_memory: True
        num_workers: 4
        persistent_workers: True
      collate_fn: 'train_collate_fn'
    validloader:
      kwargs:
        batch_size: 1
        shuffle: False
        pin_memory: True
        num_workers: 0
        persistent_workers: False
      collate_fn: ~

  process_fns:
    batch_augment_fn: # input: (input, *other, **kwargs)
      name: 'my_augment_fn'
      module: 'custom.dataprocess.template'
      kwargs: {}
    train_collate_fn: # input: (batch, **kwargs)
      name: 'default_collate'
      module: 'torch.utils.data'
      kwargs: {}

WandB:
  project: &P 'Template_project'
  track_params: True
  init_kwargs:
    config:
      runner: *Runner
  watch_kwargs:
    log: 'all'
    log_freq: 1000

